{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nall written function are here \\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "all written function are here \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded columns (including label): {'SrcAddr', 'Dir', 'Attack Category', 'SrcMac', 'DstMac', 'Flgs', 'Sport', 'Label', 'DstAddr'}\n"
     ]
    }
   ],
   "source": [
    "# cleaning and pre processing data\n",
    "\n",
    "dataPath = \"data.csv\"\n",
    "data = pd.read_csv(dataPath)\n",
    "\n",
    "# seperating features\n",
    "label_column = 'Label' \n",
    "features = data.drop(columns=[label_column]).select_dtypes(include=['float64', 'int64'])\n",
    "Labels = data[label_column]\n",
    "# Add this to see excluded columns\n",
    "excluded_columns = set(data.columns) - set(features.columns)\n",
    "print(\"Excluded columns (including label):\", excluded_columns)\n",
    "\n",
    "#standardize\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_results(confusion_matrix, classification_report, accuracy):\n",
    "    #prints the cm results, classification report, and accuracy\n",
    "    tn, fp, fn, tp = confusion_matrix.ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "    \n",
    "    # Calculate percentages\n",
    "    tn_pct = (tn/total) * 100\n",
    "    fp_pct = (fp/total) * 100\n",
    "    fn_pct = (fn/total) * 100\n",
    "    tp_pct = (tp/total) * 100\n",
    "    \n",
    "    # Print confusion matrix results\n",
    "    print(\"\\nConfusion Matrix Results:\")\n",
    "    print(f\"\"\"\n",
    "    True Negatives: {tn} ({tn_pct:.2f}%)\n",
    "    False Positives: {fp} ({fp_pct:.2f}%)\n",
    "    False Negatives: {fn} ({fn_pct:.2f}%)\n",
    "    True Positives: {tp} ({tp_pct:.2f}%)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report)\n",
    "    \n",
    "    # Print accuracy\n",
    "    print(f\"\\nModel Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n_features(data_scaled, features, n):\n",
    "    \n",
    "    # -----------------applying PCA-----------------------\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(data_scaled)\n",
    "    \n",
    "    # Getting the top n features based on explained variance\n",
    "    components = pca.components_\n",
    "    #doesprint(components)\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    \n",
    "    feature_importance = pd.DataFrame()\n",
    "    for i in range(n):\n",
    "        feature_importance[f'PC{i+1}'] = abs(components[i])\n",
    "    \n",
    "    feature_importance.index = features.columns\n",
    "    \n",
    "    # Getting overall importance by summing across components\n",
    "    feature_importance['Overall_Importance'] = feature_importance.sum(axis=1)\n",
    "    feature_importance = feature_importance.sort_values('Overall_Importance', ascending=False)\n",
    "\n",
    "    print(f\"Total explained variance ratio: {sum(explained_variance):.2%}\")\n",
    "    print(\"\\nExplained variance ratio by component:\")\n",
    "    for i, var in enumerate(explained_variance):\n",
    "        print(f\"PC{i+1}: {var:.2%}\")\n",
    "    \n",
    "    print(f\"\\nTop {n} most important features:\")\n",
    "    top_n_features = feature_importance['Overall_Importance'].head(n)\n",
    "    print(top_n_features)\n",
    "    \n",
    "    # printing out the combinations\n",
    "    print(\"\\nPrincipal Component Linear Combinations:\")\n",
    "    \n",
    "    for pc in range(3): #only want to print the top three\n",
    "        print(f\"\\nPC{pc+1} = \", end=\"\")\n",
    "        # Get the components for this PC\n",
    "        coefficients = components[pc]\n",
    "        terms = []\n",
    "        for feat, coef in zip(features.columns, coefficients):\n",
    "            if abs(coef) > 0.1: #only print if higher than .1\n",
    "                terms.append(f\"({coef:.3f} × {feat})\")\n",
    "        print(\" + \".join(terms))\n",
    "    \n",
    "    return feature_importance, top_n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explained variance ratio: 87.71%\n",
      "\n",
      "Explained variance ratio by component:\n",
      "PC1: 24.29%\n",
      "PC2: 14.41%\n",
      "PC3: 12.17%\n",
      "PC4: 8.41%\n",
      "PC5: 8.28%\n",
      "PC6: 5.97%\n",
      "PC7: 3.95%\n",
      "PC8: 3.71%\n",
      "PC9: 3.33%\n",
      "PC10: 3.18%\n",
      "\n",
      "Top 10 most important features:\n",
      "Temp          1.598481\n",
      "SrcBytes      1.539131\n",
      "ST            1.538129\n",
      "Pulse_Rate    1.483176\n",
      "Heart_rate    1.481323\n",
      "SYS           1.459602\n",
      "sMinPktSz     1.453595\n",
      "SIntPkt       1.451182\n",
      "SrcLoad       1.441597\n",
      "DIA           1.384256\n",
      "Name: Overall_Importance, dtype: float64\n",
      "\n",
      "Principal Component Linear Combinations:\n",
      "\n",
      "PC1 = (0.141 × SrcBytes) + (0.258 × DstBytes) + (0.162 × SIntPkt) + (0.265 × DIntPkt) + (0.291 × SIntPktAct) + (0.293 × SrcJitter) + (0.278 × DstJitter) + (0.139 × sMaxPktSz) + (0.293 × Dur) + (0.246 × TotPkts) + (0.212 × TotBytes) + (0.305 × Loss) + (0.301 × pLoss) + (0.259 × pSrcLoss) + (0.288 × pDstLoss)\n",
      "\n",
      "PC2 = (-0.272 × SrcBytes) + (-0.240 × DstBytes) + (0.210 × SrcLoad) + (0.313 × DstLoad) + (0.220 × SIntPkt) + (0.187 × SIntPktAct) + (0.185 × SrcJitter) + (-0.264 × sMaxPktSz) + (0.221 × sMinPktSz) + (-0.145 × Dur) + (-0.288 × TotPkts) + (-0.293 × TotBytes) + (0.277 × Load) + (0.182 × Loss) + (0.176 × pLoss) + (0.130 × pSrcLoss) + (0.187 × pDstLoss) + (0.315 × Rate)\n",
      "\n",
      "PC3 = (0.182 × SrcBytes) + (0.197 × DstBytes) + (0.190 × SrcLoad) + (0.361 × DstLoad) + (0.231 × SIntPkt) + (0.200 × DIntPkt) + (-0.187 × SIntPktAct) + (-0.186 × SrcJitter) + (0.194 × DstJitter) + (0.247 × sMaxPktSz) + (0.284 × sMinPktSz) + (0.166 × TotPkts) + (0.212 × TotBytes) + (0.283 × Load) + (-0.190 × Loss) + (-0.186 × pLoss) + (-0.158 × pSrcLoss) + (-0.181 × pDstLoss) + (0.350 × Rate)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(                     PC1           PC2           PC3           PC4  \\\n",
       " Temp        9.752076e-04  8.023737e-03  4.697304e-03  4.237827e-02   \n",
       " SrcBytes    1.414744e-01  2.715990e-01  1.818744e-01  2.064207e-01   \n",
       " ST          2.909069e-03  3.490860e-03  1.590248e-02  1.491996e-01   \n",
       " Pulse_Rate  1.989962e-02  1.454387e-02  4.781668e-02  2.109341e-01   \n",
       " Heart_rate  3.795804e-03  8.790430e-03  3.214958e-02  2.356195e-01   \n",
       " SYS         7.325385e-04  2.827284e-03  2.286887e-02  2.413371e-01   \n",
       " sMinPktSz   4.950353e-02  2.206650e-01  2.842022e-01  2.969146e-01   \n",
       " SIntPkt     1.624856e-01  2.195511e-01  2.309146e-01  2.653060e-01   \n",
       " SrcLoad     9.953613e-02  2.098301e-01  1.901392e-01  3.476696e-01   \n",
       " DIA         3.022616e-03  1.838004e-03  1.514936e-02  1.679295e-01   \n",
       " Load        8.287298e-02  2.770905e-01  2.825988e-01  2.679442e-01   \n",
       " dMaxPktSz   7.533153e-04  1.414897e-02  8.438368e-04  1.808125e-02   \n",
       " sMaxPktSz   1.389667e-01  2.636301e-01  2.470389e-01  1.298151e-01   \n",
       " Dur         2.931145e-01  1.451916e-01  9.878703e-02  9.149736e-02   \n",
       " Resp_Rate   2.894480e-03  1.083429e-02  1.558241e-02  1.544429e-02   \n",
       " TotBytes    2.119206e-01  2.929477e-01  2.122884e-01  1.474296e-01   \n",
       " DstJitter   2.784804e-01  2.607365e-02  1.936102e-01  2.535354e-01   \n",
       " DIntPkt     2.654090e-01  8.657687e-02  2.000777e-01  2.827472e-01   \n",
       " SpO2        7.130465e-03  1.085695e-02  1.289438e-02  1.050039e-01   \n",
       " DstBytes    2.579774e-01  2.403201e-01  1.970076e-01  1.428217e-02   \n",
       " Packet_num  6.433389e-03  1.032679e-02  5.135116e-02  3.116354e-01   \n",
       " TotPkts     2.463131e-01  2.883603e-01  1.658670e-01  1.089378e-01   \n",
       " Rate        4.989523e-02  3.148014e-01  3.496682e-01  1.295347e-01   \n",
       " pSrcLoss    2.591952e-01  1.301428e-01  1.577325e-01  1.232294e-01   \n",
       " pLoss       3.014590e-01  1.758769e-01  1.855218e-01  1.065739e-01   \n",
       " Loss        3.052648e-01  1.819223e-01  1.897016e-01  1.095091e-01   \n",
       " DstLoad     2.912696e-02  3.129749e-01  3.610293e-01  4.885438e-02   \n",
       " SrcJitter   2.930064e-01  1.847159e-01  1.855655e-01  9.867644e-02   \n",
       " SIntPktAct  2.912600e-01  1.873309e-01  1.865458e-01  1.000298e-01   \n",
       " pDstLoss    2.884502e-01  1.868139e-01  1.805499e-01  7.910271e-02   \n",
       " SrcGap      2.775558e-17  1.110223e-16  1.110223e-16  4.440892e-16   \n",
       " Trans       0.000000e+00  9.289626e-27  4.135903e-25  1.852885e-21   \n",
       " DIntPktAct  2.117582e-22  1.084202e-19  4.336809e-19  1.110223e-16   \n",
       " DstGap      1.734723e-18  0.000000e+00  0.000000e+00  2.775558e-17   \n",
       " dMinPktSz   3.155444e-30  0.000000e+00  0.000000e+00  3.388132e-21   \n",
       " Dport       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       " \n",
       "                      PC5           PC6           PC7           PC8  \\\n",
       " Temp        1.404361e-01  2.665723e-01  4.293259e-01  7.199505e-02   \n",
       " SrcBytes    1.539268e-01  1.534280e-03  2.996357e-02  4.373132e-01   \n",
       " ST          2.066828e-01  3.484484e-01  9.046090e-02  1.102568e-01   \n",
       " Pulse_Rate  3.288351e-01  3.177588e-01  1.444443e-01  3.621998e-02   \n",
       " Heart_rate  2.952519e-01  2.386463e-01  2.835193e-01  4.824830e-03   \n",
       " SYS         3.794909e-01  3.582165e-01  3.440637e-01  2.564389e-02   \n",
       " sMinPktSz   1.814945e-01  1.346688e-02  2.906792e-02  2.753492e-01   \n",
       " SIntPkt     1.589857e-01  8.482869e-03  2.718867e-02  3.177045e-01   \n",
       " SrcLoad     2.553852e-01  1.887059e-02  2.512571e-02  2.264204e-01   \n",
       " DIA         2.687994e-01  5.474810e-01  2.550763e-01  4.601189e-02   \n",
       " Load        2.098266e-01  1.775771e-02  2.039602e-02  1.521519e-01   \n",
       " dMaxPktSz   2.854127e-02  1.647353e-03  1.223566e-02  1.380423e-01   \n",
       " sMaxPktSz   1.062725e-01  1.836500e-03  2.337936e-02  3.046930e-01   \n",
       " Dur         3.869003e-02  1.949756e-02  2.978454e-02  4.230534e-01   \n",
       " Resp_Rate   1.947578e-02  4.064885e-01  4.631956e-01  1.900682e-02   \n",
       " TotBytes    1.228842e-01  8.577398e-03  1.110466e-02  1.620247e-01   \n",
       " DstJitter   1.480338e-01  8.750715e-03  1.176595e-02  2.150235e-01   \n",
       " DIntPkt     1.696896e-01  3.088912e-03  4.795806e-03  1.287824e-01   \n",
       " SpO2        2.104806e-01  2.271028e-01  5.154710e-01  6.504968e-03   \n",
       " DstBytes    3.963054e-02  2.154651e-02  2.097330e-02  3.062046e-01   \n",
       " Packet_num  4.011743e-01  4.619760e-02  1.902787e-01  4.199234e-02   \n",
       " TotPkts     9.767634e-02  1.893484e-02  9.830906e-03  1.418276e-01   \n",
       " Rate        1.217673e-01  1.361692e-02  1.146274e-02  3.839325e-02   \n",
       " pSrcLoss    6.499894e-02  2.655021e-03  1.181399e-02  1.676442e-01   \n",
       " pLoss       5.834310e-02  1.446521e-03  1.398128e-03  7.822639e-02   \n",
       " Loss        5.958022e-02  9.097650e-04  8.180847e-05  5.933254e-02   \n",
       " DstLoad     6.784014e-02  1.054980e-02  6.066292e-03  2.309218e-02   \n",
       " SrcJitter   5.534335e-02  5.634107e-04  5.249319e-03  1.688628e-02   \n",
       " SIntPktAct  5.469186e-02  3.874180e-04  4.628895e-03  1.009761e-02   \n",
       " pDstLoss    4.492344e-02  1.369464e-04  6.768929e-03  3.993609e-03   \n",
       " SrcGap      2.220446e-16  2.231288e-16  8.673617e-17  4.996004e-16   \n",
       " Trans       3.070494e-21  1.951564e-18  1.595946e-16  3.989864e-17   \n",
       " DIntPktAct  5.551115e-17  9.367507e-17  1.942890e-16  1.387779e-17   \n",
       " DstGap      0.000000e+00  1.465841e-16  5.551115e-17  1.942890e-16   \n",
       " dMinPktSz   0.000000e+00  1.734723e-18  2.775558e-17  0.000000e+00   \n",
       " Dport       0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       " \n",
       "                      PC9          PC10  Overall_Importance  \n",
       " Temp        6.881160e-02  5.652659e-01        1.598481e+00  \n",
       " SrcBytes    5.618998e-02  5.883511e-02        1.539131e+00  \n",
       " ST          4.296261e-02  5.678160e-01        1.538129e+00  \n",
       " Pulse_Rate  1.635661e-02  3.463673e-01        1.483176e+00  \n",
       " Heart_rate  3.219318e-02  3.465317e-01        1.481323e+00  \n",
       " SYS         6.978984e-03  7.744248e-02        1.459602e+00  \n",
       " sMinPktSz   8.585312e-02  1.707823e-02        1.453595e+00  \n",
       " SIntPkt     2.641739e-02  3.414506e-02        1.451182e+00  \n",
       " SrcLoad     6.132899e-02  7.290782e-03        1.441597e+00  \n",
       " DIA         1.720423e-04  7.877642e-02        1.384256e+00  \n",
       " Load        3.433352e-02  1.127552e-03        1.346100e+00  \n",
       " dMaxPktSz   9.816713e-01  1.021635e-01        1.298129e+00  \n",
       " sMaxPktSz   1.319915e-02  3.478471e-02        1.263616e+00  \n",
       " Dur         7.438402e-02  4.517660e-02        1.259177e+00  \n",
       " Resp_Rate   1.375186e-02  2.793249e-01        1.245999e+00  \n",
       " TotBytes    1.976683e-02  2.744675e-02        1.216391e+00  \n",
       " DstJitter   3.589335e-02  2.550455e-02        1.196671e+00  \n",
       " DIntPkt     1.304885e-02  1.991622e-02        1.174133e+00  \n",
       " SpO2        2.497415e-02  5.343700e-02        1.173856e+00  \n",
       " DstBytes    4.169781e-02  2.855276e-02        1.168193e+00  \n",
       " Packet_num  5.138908e-04  4.893248e-02        1.108836e+00  \n",
       " TotPkts     5.836802e-03  8.027054e-03        1.091612e+00  \n",
       " Rate        1.884306e-03  6.655890e-03        1.037680e+00  \n",
       " pSrcLoss    3.353816e-02  2.838242e-02        9.793327e-01  \n",
       " pLoss       1.584090e-02  1.208705e-02        9.367736e-01  \n",
       " Loss        1.192079e-02  8.966422e-03        9.271893e-01  \n",
       " DstLoad     2.315660e-02  1.001128e-02        8.927018e-01  \n",
       " SrcJitter   4.377362e-03  2.090208e-03        8.464741e-01  \n",
       " SIntPktAct  1.499425e-03  6.115216e-04        8.370832e-01  \n",
       " pDstLoss    6.991960e-04  2.501152e-03        7.939401e-01  \n",
       " SrcGap      2.498002e-16  4.163336e-17        2.016833e-15  \n",
       " Trans       9.992007e-16  7.771561e-16        1.977807e-15  \n",
       " DIntPktAct  3.330669e-16  5.551115e-16        1.357096e-15  \n",
       " DstGap      4.024558e-16  1.110223e-16        9.393528e-16  \n",
       " dMinPktSz   5.551115e-17  2.775558e-17        1.127604e-16  \n",
       " Dport       0.000000e+00  0.000000e+00        0.000000e+00  ,\n",
       " Temp          1.598481\n",
       " SrcBytes      1.539131\n",
       " ST            1.538129\n",
       " Pulse_Rate    1.483176\n",
       " Heart_rate    1.481323\n",
       " SYS           1.459602\n",
       " sMinPktSz     1.453595\n",
       " SIntPkt       1.451182\n",
       " SrcLoad       1.441597\n",
       " DIA           1.384256\n",
       " Name: Overall_Importance, dtype: float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_top_n_features(data_scaled, features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans_clustering(data_scaled, features, labels, n_components=2):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on PCA components using selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        features: DataFrame with only the features to analyze\n",
    "        labels: target labels\n",
    "        n_components: number of PCA components to use\n",
    "    \"\"\"\n",
    "    print(\"\\nperformin k means on this many features: \", len(features.columns))\n",
    "    \n",
    "    \n",
    "    # Convert data_scaled to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=features.columns)\n",
    "    \n",
    "    # Select only the specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # PCA on selected features\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pc_features = pca.fit_transform(selected_features)\n",
    "    \n",
    "    pca_df = pd.DataFrame(\n",
    "        data=pc_features,\n",
    "        columns=[f'PC{i+1}' for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        pca_df, labels, test_size=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    # K-means clustering\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    kmeans.fit(X_train)\n",
    "    y_pred = kmeans.predict(X_test)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)    \n",
    "    accuracy = accuracy_score(y_test, y_pred)    \n",
    "    return cm, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "performin k means on this many features:  36\n",
      "\n",
      "Confusion Matrix Results:\n",
      "\n",
      "    True Negatives: 1436 (87.99%)\n",
      "    False Positives: 2 (0.12%)\n",
      "    False Negatives: 194 (11.89%)\n",
      "    True Positives: 0 (0.00%)\n",
      "    \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94      1438\n",
      "           1       0.00      0.00      0.00       194\n",
      "\n",
      "    accuracy                           0.88      1632\n",
      "   macro avg       0.44      0.50      0.47      1632\n",
      "weighted avg       0.78      0.88      0.82      1632\n",
      "\n",
      "\n",
      "Model Accuracy: 87.99%\n"
     ]
    }
   ],
   "source": [
    "cm, class_report, accuracy = perform_kmeans_clustering(data_scaled, features, data[label_column], n_components=3)\n",
    "\n",
    "print_classification_results(cm, class_report, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance, top_features = find_top_n_features(data_scaled, features, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(data_scaled, Labels, features, n_estimators):\n",
    "    \"\"\"\n",
    "    Train Random Forest on selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        Labels: target labels \n",
    "        features: DataFrame with features to analyze\n",
    "        n_estimators: number of trees in forest\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy)\n",
    "    \"\"\"\n",
    "    print(f\"Training Random Forest with {n_estimators} estimators\")\n",
    "    print(f\"Number of features used: {len(features.columns)}\")\n",
    "    \n",
    "    # Convert scaled data to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        selected_features, Labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features.columns,\n",
    "        'importance': rf_classifier.feature_importances_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "    print(\"\\nTop 5 Most Important Features:\")\n",
    "    print(feature_importance.head(5))\n",
    "    \n",
    "    return cm, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest with 100 estimators\n",
      "Number of features used: 36\n",
      "\n",
      "Top 5 Most Important Features:\n",
      "      feature  importance\n",
      "8     DIntPkt    0.133990\n",
      "21       Load    0.096434\n",
      "12  DstJitter    0.093912\n",
      "17        Dur    0.086107\n",
      "3     SrcLoad    0.082480\n",
      "\n",
      "Confusion Matrix Results:\n",
      "\n",
      "    True Negatives: 4241 (86.62%)\n",
      "    False Positives: 11 (0.22%)\n",
      "    False Negatives: 313 (6.39%)\n",
      "    True Positives: 331 (6.76%)\n",
      "    \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4252\n",
      "           1       0.97      0.51      0.67       644\n",
      "\n",
      "    accuracy                           0.93      4896\n",
      "   macro avg       0.95      0.76      0.82      4896\n",
      "weighted avg       0.94      0.93      0.92      4896\n",
      "\n",
      "\n",
      "Model Accuracy: 93.38%\n"
     ]
    }
   ],
   "source": [
    "forest_cm, forest_report, forest_accuracy = train_random_forest(data_scaled, Labels, features, 100)\n",
    "\n",
    "print_classification_results(forest_cm, forest_report, forest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_lda(data_scaled, labels, features):\n",
    "    \"\"\"\n",
    "    Perform Linear Discriminant Analysis on selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        labels: target labels\n",
    "        features: DataFrame with features to analyze\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy)\n",
    "    \"\"\"\n",
    "    print(f\"\\nPerforming LDA on {len(features.columns)} features\")\n",
    "    \n",
    "    # Convert scaled data to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # Split using the features DataFrame\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        selected_features, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Initialize and fit LDA model\n",
    "    lda = LDA()\n",
    "    lda.fit(X_train, y_train)\n",
    "\n",
    "    # Print LDA components information\n",
    "    print(\"\\nLDA Components Information:\")\n",
    "    print(f\"Number of components: {lda.n_components}\")\n",
    "    print(\"\\nExplained variance ratio:\")\n",
    "    print(lda.explained_variance_ratio_)\n",
    "    \n",
    "    # Print component coefficients\n",
    "    print(\"\\nLinear Discriminant Coefficients:\")\n",
    "    for i, component in enumerate(lda.coef_):\n",
    "        print(f\"\\nLD{i+1} coefficients:\")\n",
    "        for feat, coef in zip(features.columns, component):\n",
    "            print(f\"{feat}: {coef:.4f}\")\n",
    "\n",
    "    # Make predictions and calculate metrics\n",
    "    y_pred = lda.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return conf_matrix, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing LDA on 36 features\n",
      "\n",
      "LDA Components Information:\n",
      "Number of components: None\n",
      "\n",
      "Explained variance ratio:\n",
      "[1.]\n",
      "\n",
      "Linear Discriminant Coefficients:\n",
      "\n",
      "LD1 coefficients:\n",
      "Dport: 0.0000\n",
      "SrcBytes: 4.5746\n",
      "DstBytes: -9.3746\n",
      "SrcLoad: -0.4146\n",
      "DstLoad: -3.5580\n",
      "SrcGap: -0.0000\n",
      "DstGap: 0.0000\n",
      "SIntPkt: -2.3615\n",
      "DIntPkt: -0.4477\n",
      "SIntPktAct: 453.4666\n",
      "DIntPktAct: -0.0000\n",
      "SrcJitter: -153.6353\n",
      "DstJitter: 7.8913\n",
      "sMaxPktSz: 0.0185\n",
      "dMaxPktSz: -0.9048\n",
      "sMinPktSz: -0.7674\n",
      "dMinPktSz: 0.0000\n",
      "Dur: 2.0393\n",
      "Trans: 0.0000\n",
      "TotPkts: 2.6564\n",
      "TotBytes: -1.0525\n",
      "Load: -2.3268\n",
      "Loss: -552.0637\n",
      "pLoss: 1173.2676\n",
      "pSrcLoss: -384.6796\n",
      "pDstLoss: -600.8920\n",
      "Rate: 4.7021\n",
      "Packet_num: -0.0375\n",
      "Temp: -0.0457\n",
      "SpO2: 0.0027\n",
      "Pulse_Rate: 0.2497\n",
      "SYS: -0.0287\n",
      "DIA: 0.1639\n",
      "Heart_rate: 0.0998\n",
      "Resp_Rate: 0.0286\n",
      "ST: 0.2382\n",
      "\n",
      "Confusion Matrix Results:\n",
      "\n",
      "    True Negatives: 4233 (86.46%)\n",
      "    False Positives: 19 (0.39%)\n",
      "    False Negatives: 351 (7.17%)\n",
      "    True Positives: 293 (5.98%)\n",
      "    \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      4252\n",
      "           1       0.94      0.45      0.61       644\n",
      "\n",
      "    accuracy                           0.92      4896\n",
      "   macro avg       0.93      0.73      0.79      4896\n",
      "weighted avg       0.93      0.92      0.91      4896\n",
      "\n",
      "\n",
      "Model Accuracy: 92.44%\n"
     ]
    }
   ],
   "source": [
    "cm, report, accuracy = perform_lda(data_scaled, Labels, features)\n",
    "\n",
    "print_classification_results(cm, report, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_naive_bayes(data_scaled, labels, features):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Naive Bayes on selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        labels: target labels\n",
    "        features: DataFrame with features to analyze\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy)\n",
    "    \"\"\"\n",
    "    print(f\"\\nPerforming Gaussian Naive Bayes on {len(features.columns)} features\")\n",
    "    \n",
    "    # Convert scaled data to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        selected_features, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Initialize and fit GNB model\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate metrics\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return cm, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing Gaussian Naive Bayes on 36 features\n",
      "\n",
      "Confusion Matrix Results:\n",
      "\n",
      "    True Negatives: 3843 (78.49%)\n",
      "    False Positives: 409 (8.35%)\n",
      "    False Negatives: 338 (6.90%)\n",
      "    True Positives: 306 (6.25%)\n",
      "    \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      4252\n",
      "           1       0.43      0.48      0.45       644\n",
      "\n",
      "    accuracy                           0.85      4896\n",
      "   macro avg       0.67      0.69      0.68      4896\n",
      "weighted avg       0.85      0.85      0.85      4896\n",
      "\n",
      "\n",
      "Model Accuracy: 84.74%\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "cm, report, acc = gaussian_naive_bayes(data_scaled, Labels, features)\n",
    "print_classification_results(cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVC(data_scaled, features, labels):\n",
    "    \"\"\"\n",
    "    Train SVC models with different kernels using selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        features: DataFrame with features to analyze\n",
    "        labels: target labels\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy) for best kernel\n",
    "    \"\"\"\n",
    "    print(\"\\nPerforming SVC on this many features: \", len(features.columns))\n",
    "    \n",
    "    # Convert data_scaled to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        selected_features, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    kernelTypes = ['linear', 'rbf', 'poly']\n",
    "    best_accuracy = 0\n",
    "    best_metrics = None\n",
    "    \n",
    "    print(\"\\nTraining SVC models with different kernels...\")\n",
    "    for kernelType in tqdm(kernelTypes, desc='Training'):\n",
    "        model = SVC(kernel=kernelType, C=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nKernel: {kernelType}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        \n",
    "    return cm, report, accuracy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing SVC on this many features:  36\n",
      "\n",
      "Training SVC models with different kernels...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  33%|███▎      | 1/3 [00:06<00:12,  6.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel: linear\n",
      "Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  67%|██████▋   | 2/3 [00:08<00:03,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel: rbf\n",
      "Accuracy: 0.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 3/3 [00:09<00:00,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Kernel: poly\n",
      "Accuracy: 0.93\n",
      "\n",
      "Confusion Matrix Results:\n",
      "\n",
      "    True Negatives: 4244 (86.68%)\n",
      "    False Positives: 8 (0.16%)\n",
      "    False Negatives: 342 (6.99%)\n",
      "    True Positives: 302 (6.17%)\n",
      "    \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      4252\n",
      "           1       0.97      0.47      0.63       644\n",
      "\n",
      "    accuracy                           0.93      4896\n",
      "   macro avg       0.95      0.73      0.80      4896\n",
      "weighted avg       0.93      0.93      0.92      4896\n",
      "\n",
      "\n",
      "Model Accuracy: 92.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Usage:\n",
    "cm, report, acc = train_SVC(data_scaled, features, Labels)\n",
    "print_classification_results(cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(data_scaled, labels, features):\n",
    "    \"\"\"\n",
    "    Perform CNN classification on selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        labels: target labels\n",
    "        features: DataFrame with features to analyze\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy)\n",
    "    \"\"\"\n",
    "    print(f\"\\nPerforming CNN on {len(features.columns)} features\")\n",
    "    \n",
    "    # Convert scaled data to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns].values\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(labels)\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "    # Reshape data for CNN\n",
    "    num_features = selected_features.shape[1]\n",
    "    grid_size = int(np.ceil(np.sqrt(num_features)))\n",
    "    X_padded = np.zeros((selected_features.shape[0], grid_size * grid_size))\n",
    "    X_padded[:, :num_features] = selected_features\n",
    "    X_reshaped = X_padded.reshape(-1, grid_size, grid_size, 1)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_reshaped, y_categorical, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Build CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(grid_size, grid_size, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, \n",
    "                       validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred_proba = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_test_labels, y_pred)\n",
    "    class_report = classification_report(y_test_labels, y_pred)\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    \n",
    "    return cm, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Performing CNN on 36 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\allen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix Results:\n",
      "\n",
      "    True Negatives: 4225 (86.29%)\n",
      "    False Positives: 27 (0.55%)\n",
      "    False Negatives: 299 (6.11%)\n",
      "    True Positives: 345 (7.05%)\n",
      "    \n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      4252\n",
      "           1       0.93      0.54      0.68       644\n",
      "\n",
      "    accuracy                           0.93      4896\n",
      "   macro avg       0.93      0.76      0.82      4896\n",
      "weighted avg       0.93      0.93      0.93      4896\n",
      "\n",
      "\n",
      "Model Accuracy: 93.34%\n"
     ]
    }
   ],
   "source": [
    "# Run the CNN model\n",
    "cnn_cm, cnn_report, cnn_accuracy = CNN(data_scaled, Labels, features)\n",
    "\n",
    "# Print the results\n",
    "print_classification_results(cnn_cm, cnn_report, cnn_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
