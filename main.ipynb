{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "all written function are here \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded columns (including label): {'Flgs', 'SrcMac', 'Dir', 'SrcAddr', 'Sport', 'DstAddr', 'Attack Category', 'Label', 'DstMac'}\n",
      "Index(['DIntPkt', 'Load', 'DstJitter', 'Dur', 'SrcLoad', 'Rate', 'Packet_num',\n",
      "       'SIntPkt', 'DstLoad', 'SrcJitter'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# cleaning and pre processing data\n",
    "\n",
    "dataPath = \"data.csv\"\n",
    "data = pd.read_csv(dataPath)\n",
    "\n",
    "# seperating features\n",
    "label_column = 'Label' \n",
    "data_features = data.drop(columns=[label_column]).select_dtypes(include=['float64', 'int64'])\n",
    "Labels = data[label_column]\n",
    "# Add this to see excluded columns\n",
    "excluded_columns = set(data.columns) - set(data_features.columns)\n",
    "print(\"Excluded columns (including label):\", excluded_columns)\n",
    "\n",
    "#standardize\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_features)\n",
    "\n",
    "top_10_features_list = ['DIntPkt', 'Load', 'DstJitter', 'Dur', 'SrcLoad', \n",
    "                     'Rate', 'Packet_num', 'SIntPkt', 'DstLoad', 'SrcJitter']\n",
    "top_10_features = pd.DataFrame(data_features, columns=top_10_features_list)\n",
    "\n",
    "top_5_features = pd.DataFrame(data_features, columns=top_10_features_list[:5])\n",
    "\n",
    "\n",
    "print(top_10_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_results(confusion_matrix, classification_report, accuracy):\n",
    "    #prints the cm results, classification report, and accuracy\n",
    "    tn, fp, fn, tp = confusion_matrix.ravel()\n",
    "    total = tn + fp + fn + tp\n",
    "    \n",
    "    # Calculate percentages\n",
    "    tn_pct = (tn/total) * 100\n",
    "    fp_pct = (fp/total) * 100\n",
    "    fn_pct = (fn/total) * 100\n",
    "    tp_pct = (tp/total) * 100\n",
    "    \n",
    "    # Print confusion matrix results\n",
    "    print(\"\\nConfusion Matrix Results:\")\n",
    "    print(f\"\"\"\n",
    "    True Negatives: {tn} ({tn_pct:.2f}%)\n",
    "    False Positives: {fp} ({fp_pct:.2f}%)\n",
    "    False Negatives: {fn} ({fn_pct:.2f}%)\n",
    "    True Positives: {tp} ({tp_pct:.2f}%)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Print classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report)\n",
    "    \n",
    "    # Print accuracy\n",
    "    print(f\"\\nModel Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_top_n_features(data_scaled, features, n):\n",
    "    pca = PCA(n_components=n)\n",
    "    pca.fit(data_scaled)\n",
    "    \n",
    "    components = pca.components_\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    \n",
    "    feature_importance = pd.DataFrame()\n",
    "    for i in range(n):\n",
    "        feature_importance[f'PC{i+1}'] = abs(components[i])\n",
    "    \n",
    "    feature_importance.index = features.columns\n",
    "    feature_importance['Overall_Importance'] = feature_importance.sum(axis=1)\n",
    "    feature_importance = feature_importance.sort_values('Overall_Importance', ascending=False)\n",
    "\n",
    "    print(f\"Total explained variance ratio: {sum(explained_variance):.2%}\")\n",
    "    print(\"\\nExplained variance ratio by component:\")\n",
    "    for i, var in enumerate(explained_variance):\n",
    "        print(f\"PC{i+1}: {var:.2%}\")\n",
    "    \n",
    "    print(f\"\\nTop {n} most important features:\")\n",
    "    top_n_features = feature_importance['Overall_Importance'].head(n)\n",
    "    print(top_n_features)\n",
    "    \n",
    "    # Add semicolon to suppress output\n",
    "    return feature_importance, top_n_features;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total explained variance ratio: 87.71%\n",
      "\n",
      "Explained variance ratio by component:\n",
      "PC1: 24.29%\n",
      "PC2: 14.41%\n",
      "PC3: 12.17%\n",
      "PC4: 8.41%\n",
      "PC5: 8.28%\n",
      "PC6: 5.97%\n",
      "PC7: 3.95%\n",
      "PC8: 3.71%\n",
      "PC9: 3.33%\n",
      "PC10: 3.18%\n",
      "\n",
      "Top 10 most important features:\n",
      "Temp          1.598481\n",
      "SrcBytes      1.539131\n",
      "ST            1.538129\n",
      "Pulse_Rate    1.483176\n",
      "Heart_rate    1.481323\n",
      "SYS           1.459602\n",
      "sMinPktSz     1.453595\n",
      "SIntPkt       1.451182\n",
      "SrcLoad       1.441597\n",
      "DIA           1.384256\n",
      "Name: Overall_Importance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "featureImportance, top_n = find_top_n_features(data_scaled, data_features, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_kmeans_clustering(data_scaled, features, labels, n_components=2):\n",
    "    \"\"\"\n",
    "    Perform K-means clustering on PCA components using selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        features: DataFrame with only the features to analyze\n",
    "        labels: target labels\n",
    "        n_components: number of PCA components to use\n",
    "    \"\"\"\n",
    "    print(\"\\nperformin k means on this many features: \", len(features.columns))\n",
    "    \n",
    "    \n",
    "    # Convert data_scaled to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=data_features.columns)\n",
    "    \n",
    "    # Select only the specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # PCA on selected features\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pc_features = pca.fit_transform(selected_features)\n",
    "    \n",
    "    pca_df = pd.DataFrame(\n",
    "        data=pc_features,\n",
    "        columns=[f'PC{i+1}' for i in range(n_components)]\n",
    "    )\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        pca_df, labels, test_size=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    # K-means clustering\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "    kmeans.fit(X_train)\n",
    "    y_pred = kmeans.predict(X_test)\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)    \n",
    "    accuracy = accuracy_score(y_test, y_pred)    \n",
    "    return cm, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, class_report, accuracy = perform_kmeans_clustering(data_scaled, data_features, data[label_column], n_components=3)\n",
    "\n",
    "print_classification_results(cm, class_report, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance, top_features = find_top_n_features(data_scaled, features, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_random_forest(data_scaled, Labels, features, n_estimators):\n",
    "    \"\"\"\n",
    "    Train Random Forest on selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        Labels: target labels \n",
    "        features: DataFrame with features to analyze\n",
    "        n_estimators: number of trees in forest\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy)\n",
    "    \"\"\"\n",
    "    print(f\"Training Random Forest with {n_estimators} estimators\")\n",
    "    print(f\"Number of features used: {len(features.columns)}\")\n",
    "    \n",
    "    # Convert scaled data to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=data_features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        selected_features, Labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    rf_classifier = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Print feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': features.columns,\n",
    "        'importance': rf_classifier.feature_importances_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "    print(\"\\nTop 5 Most Important Features:\")\n",
    "    print(feature_importance.head(5))\n",
    "    \n",
    "    return cm, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_cm, forest_report, forest_accuracy = train_random_forest(data_scaled, Labels, data_features, 100)\n",
    "\n",
    "print_classification_results(forest_cm, forest_report, forest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_lda(data_scaled, labels, features):\n",
    "    \"\"\"\n",
    "    Perform Linear Discriminant Analysis on selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        labels: target labels\n",
    "        features: DataFrame with features to analyze\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy)\n",
    "    \"\"\"\n",
    "    print(f\"\\nPerforming LDA on {len(features.columns)} features\")\n",
    "    \n",
    "    # Convert scaled data to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=data_features.columns)\n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns].values\n",
    "    \n",
    "    # Split using the features DataFrame\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        selected_features, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Initialize and fit LDA model\n",
    "    lda = LDA()\n",
    "    lda.fit(X_train, y_train)\n",
    "\n",
    "    # Print LDA components information\n",
    "    print(\"\\nLDA Components Information:\")\n",
    "    print(f\"Number of components: {lda.n_components}\")\n",
    "    print(\"\\nExplained variance ratio:\")\n",
    "    print(lda.explained_variance_ratio_)\n",
    "    \n",
    "    # Print component coefficients\n",
    "    print(\"\\nLinear Discriminant Coefficients:\")\n",
    "    for i, component in enumerate(lda.coef_):\n",
    "        print(f\"\\nLD{i+1} coefficients:\")\n",
    "        for feat, coef in zip(features.columns, component):\n",
    "            print(f\"{feat}: {coef:.4f}\")\n",
    "\n",
    "    # Make predictions and calculate metrics\n",
    "    y_pred = lda.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return conf_matrix, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, report, accuracy = perform_lda(data_scaled, Labels, top_10_features)\n",
    "\n",
    "print_classification_results(cm, report, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_naive_bayes(data_scaled, labels, features):\n",
    "    \"\"\"\n",
    "    Perform Gaussian Naive Bayes on selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        labels: target labels\n",
    "        features: DataFrame with features to analyze\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy)\n",
    "    \"\"\"\n",
    "    print(f\"\\nPerforming Gaussian Naive Bayes on {len(features.columns)} features\")\n",
    "    \n",
    "    # Convert scaled data to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=data_features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        selected_features, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "    \n",
    "    # Initialize and fit GNB model\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions and calculate metrics\n",
    "    y_pred = gnb.predict(X_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    return cm, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "cm, report, acc = gaussian_naive_bayes(data_scaled, Labels, top_10_features)\n",
    "print_classification_results(cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVC(data_scaled, features, labels):\n",
    "    \"\"\"\n",
    "    Train SVC models with different kernels using selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        features: DataFrame with features to analyze\n",
    "        labels: target labels\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy) for best kernel\n",
    "    \"\"\"\n",
    "    print(\"\\nPerforming SVC on this many features: \", len(features.columns))\n",
    "    \n",
    "    # Convert data_scaled to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=data_features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns]\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        selected_features, labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    kernelTypes = ['linear', 'rbf', 'poly']\n",
    "    best_accuracy = 0\n",
    "    best_metrics = None\n",
    "    \n",
    "    print(\"\\nTraining SVC models with different kernels...\")\n",
    "    for kernelType in tqdm(kernelTypes, desc='Training'):\n",
    "        model = SVC(kernel=kernelType, C=1)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        print(f\"\\nKernel: {kernelType}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}\")\n",
    "        \n",
    "    return cm, report, accuracy\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage:\n",
    "cm, report, acc = train_SVC(data_scaled, data_features, Labels)\n",
    "print_classification_results(cm, report, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN(data_scaled, labels, features):\n",
    "    \"\"\"\n",
    "    Perform CNN classification on selected features\n",
    "    \n",
    "    Args:\n",
    "        data_scaled: scaled numpy array from StandardScaler\n",
    "        labels: target labels\n",
    "        features: DataFrame with features to analyze\n",
    "    Returns:\n",
    "        tuple: (confusion_matrix, classification_report, accuracy)\n",
    "    \"\"\"\n",
    "    print(f\"\\nPerforming CNN on {len(features.columns)} features\")\n",
    "    \n",
    "    # Convert scaled data to DataFrame with feature names\n",
    "    scaled_df = pd.DataFrame(data_scaled, columns=data_features.columns)\n",
    "    \n",
    "    # Select only specified features\n",
    "    selected_features = scaled_df[features.columns].values\n",
    "    \n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(labels)\n",
    "    y_categorical = to_categorical(y_encoded)\n",
    "\n",
    "    # Reshape data for CNN\n",
    "    num_features = selected_features.shape[1]\n",
    "    grid_size = int(np.ceil(np.sqrt(num_features)))\n",
    "    X_padded = np.zeros((selected_features.shape[0], grid_size * grid_size))\n",
    "    X_padded[:, :num_features] = selected_features\n",
    "    X_reshaped = X_padded.reshape(-1, grid_size, grid_size, 1)\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_reshaped, y_categorical, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Build CNN model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(grid_size, grid_size, 1)))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Conv2D(64, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(y_categorical.shape[1], activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(X_train, y_train, epochs=20, batch_size=32, \n",
    "                       validation_data=(X_test, y_test), verbose=0)\n",
    "\n",
    "    # Get predictions\n",
    "    y_pred_proba = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Calculate metrics\n",
    "    cm = confusion_matrix(y_test_labels, y_pred)\n",
    "    class_report = classification_report(y_test_labels, y_pred)\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "    \n",
    "    return cm, class_report, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the CNN model\n",
    "cnn_cm, cnn_report, cnn_accuracy = CNN(data_scaled, Labels, data_features)\n",
    "\n",
    "# Print the results\n",
    "print_classification_results(cnn_cm, cnn_report, cnn_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
